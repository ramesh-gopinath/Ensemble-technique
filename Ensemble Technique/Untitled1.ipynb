{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "971f4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(random_state=2)\n",
      "DecisionTreeClassifier\n",
      "GradientBoostingClassifier(learning_rate=0.04, n_estimators=75, random_state=1)\n",
      "GradientBoostingClassifier\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eed=27,\n",
      "              enable_categorical=False, gamma=0, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.1, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, subsample=0.8,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)\n",
      "XGBClassifier\n",
      "KNeighborsClassifier(weights='distance')\n",
      "KNeighborsClassifier\n",
      "LogisticRegression(solver='liblinear')\n",
      "LogisticRegression\n",
      "SVC(kernel='linear')\n",
      "SVC\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC  \n",
    "\n",
    "mod = [DecisionTreeClassifier(criterion = 'gini', random_state=2),\n",
    "       GradientBoostingClassifier(n_estimators = 75, learning_rate = 0.04, random_state=1),\n",
    "       XGBClassifier(learning_rate =0.1,n_estimators=200,max_depth=5,min_child_weight=1,gamma=0,subsample=0.8,colsample_bytree=0.8,objective='binary:logistic',nthread=4,scale_pos_weight=1,eed=27),\n",
    "       KNeighborsClassifier(n_neighbors= 5, weights = 'distance' ),\n",
    "       LogisticRegression(solver='liblinear'),\n",
    "       SVC(kernel='linear')]\n",
    "\n",
    "\n",
    "for i in mod:\n",
    "    print(i)\n",
    "    new_i = str(i)\n",
    "    sub_i = new_i[0:new_i.find(\"(\")]\n",
    "    #sub_i = re.search(r'\\(',new_i)\n",
    "    print(sub_i)\n",
    "    #model = i\n",
    "    #i.fit(1,4)\n",
    "            \n",
    "    #model = mod[key]\n",
    "    #print(model)\n",
    "    #params = [model.__class__.__name__][0]\n",
    "    #print(\"params\",params)\n",
    "    #model1 = mod[key]**ast.literal_eval(\"{\"+i.split(\"(\", 1)[1][:-1].replace(\"=\",\":\")+\"}\")\n",
    "    #print(model1)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
